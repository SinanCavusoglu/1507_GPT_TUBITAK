{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Wiki Dataset and Law Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.normalizers import (Sequence, NFD)\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_law_par = pd.read_parquet(r\"c:\\Users\\siren\\Desktop\\1507\\dataset\\hukuk_raw_dataset\\train.parquet\", engine=\"pyarrow\")\n",
    "wiki_par = pd.read_parquet(r\"C:\\Users\\siren\\Desktop\\1507\\dataset\\ts_wikipedia\\bpe_support.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_par = wiki_par.drop([2372009])\n",
    "train_law_par=train_law_par.drop(columns = [\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([wiki_par,train_law_par])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cengiz Han Moğol Börçigin ailesinden siyasetçi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moğol kabilelerini buyruğu altında birleştirer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu imparatorluk Dünya tarihinin bitişik sınırl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timuçin ismiyle Moğol Devleti hükümdarı akraba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tüm dünya tarafından genelde acımasız ve kana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396531</th>\n",
       "      <td>uzatmayı öngören hükümlere sözleşmede yer verm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396532</th>\n",
       "      <td>163 Tam yargı davası 2577 sayılı İdari Yargıla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396533</th>\n",
       "      <td>sürdürmesinden ibaret ve bu hakkın kişinin öze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396534</th>\n",
       "      <td>2. Portföy Yönetim Şirketleri ve Bireysel Katı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396535</th>\n",
       "      <td>115  nitelendirmelerde bulunmaktadır576. Bu se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5396536 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        Cengiz Han Moğol Börçigin ailesinden siyasetçi...\n",
       "1        Moğol kabilelerini buyruğu altında birleştirer...\n",
       "2        Bu imparatorluk Dünya tarihinin bitişik sınırl...\n",
       "3        Timuçin ismiyle Moğol Devleti hükümdarı akraba...\n",
       "4        Tüm dünya tarafından genelde acımasız ve kana ...\n",
       "...                                                    ...\n",
       "5396531  uzatmayı öngören hükümlere sözleşmede yer verm...\n",
       "5396532  163 Tam yargı davası 2577 sayılı İdari Yargıla...\n",
       "5396533  sürdürmesinden ibaret ve bu hakkın kişinin öze...\n",
       "5396534  2. Portföy Yönetim Şirketleri ve Bireysel Katı...\n",
       "5396535  115  nitelendirmelerde bulunmaktadır576. Bu se...\n",
       "\n",
       "[5396536 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[UNK]\", \"<|endoftext|>\"]\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.normalizer = Sequence([NFD()])\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.decoder = BPEDecoder()\n",
    "tokenizer.post_processor = TemplateProcessing(single=\"$A <|endoftext|>\",  \n",
    "                                              special_tokens=[(\"<|endoftext|>\", 1)]  \n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BpeTrainer(vocab_size=52000,\n",
    "                     min_frequency = 1,\n",
    "                     special_tokens=special_tokens,\n",
    "                     continuing_subword_prefix=\"##\",\n",
    "                     max_token_length = 6,\n",
    "                     show_progress = True)\n",
    "tokenizer.train_from_iterator(all_df[\"text\"].astype(str), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model.save('.')\n",
    "tokenizer.save(\"MyBPETokenizerWikiLaw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerFromFile = Tokenizer.from_file(\"MyBPETokenizerWikiLaw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ['Hukuk', 'bir', 'gün', 'herk', '##ese', 'lazım', 'olur', '.', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "sen_enc3 = tokenizerFromFile.encode(\"Hukuk bir gün herkese lazım olur.\")\n",
    "print(f\"Output: {format(sen_enc3.tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ['Bırak', '##ın', 'ada', '##let', 'yer', '##ini', 'bul', '##sun', ',', 'ister', '##se', 'kıya', '##met', 'kop', '##sun', '.', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "sen_enc3 = tokenizerFromFile.encode(\"Bırakın adalet yerini bulsun, isterse kıyamet kopsun.\")\n",
    "print(f\"Output: {format(sen_enc3.tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ['Ada', '##let', 'önce', 'dev', '##let', '##ten', 'gelir', '.', 'Çün', '##kü', 'hukuk', ',', 'dev', '##letin', 'top', '##lum', '##sal', 'düz', '##eni', '##dir', '.', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "sen_enc3 = tokenizerFromFile.encode(\"Adalet önce devletten gelir. Çünkü hukuk, devletin toplumsal düzenidir.\")\n",
    "print(f\"Output: {format(sen_enc3.tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=664, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizerFromFile.encode(train_law_par.iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tubitak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
